{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OsnBYmFzxIq"
      },
      "source": [
        "## **Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "STOPWORDS =(stopwords.words('english'))\n",
        "\n",
        "\n",
        "import textstat\n",
        "textstat.set_lang('en')\n",
        "from collections import Counter\n",
        "from spellchecker import SpellChecker\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report, precision_score, f1_score, recall_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syxglSLiz7z9"
      },
      "source": [
        "## **Read Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyH8Z7w4eoUV",
        "outputId": "ff9b487a-7778-4da3-cd6b-4c22e65f6011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19279\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['Id', 'newsText', 'Label'], dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir_name = r\"data/Gossipcop.csv\"\n",
        "df = pd.read_csv(dir_name,encoding='utf-16')\n",
        "df = df.dropna()\n",
        "print(len(df))\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6_K6vUQrdTQ"
      },
      "source": [
        "## **Preprocess**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLxEKE2Ny57z"
      },
      "outputs": [],
      "source": [
        "old_txt = df['newsText']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxJaPIfRQCb0",
        "outputId": "18f90cf2-9a19-49ff-a699-f1346a1fd624"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-46-f90be5f38007>:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  beauti = BeautifulSoup(data,'html.parser')\n"
          ]
        }
      ],
      "source": [
        "# to remove HTML tag\n",
        "def html_remover(data):\n",
        "  beauti = BeautifulSoup(data,'html.parser')\n",
        "  return beauti.get_text()\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "\n",
        "def lemmatizer(text):\n",
        "    doc = nlp(text)\n",
        "    lemmatized_sentence = \" \".join([token.lemma_.lower() if token.lemma_ != '-PRON-' else token.lower_ for token in doc])\n",
        "    return(lemmatized_sentence)\n",
        "\n",
        "\n",
        "new_txt = []\n",
        "\n",
        "new_txt = old_txt.apply(lambda x: html_remover(x))\n",
        "new_txt = new_txt.apply(lambda x: re.sub(r'https\\S*',' ',x))\n",
        "new_txt = new_txt.apply(lambda x: re.sub(r'http\\S*',' ',x))\n",
        "new_txt = new_txt.apply(lambda x: re.sub(r'www.\\S*com\\S*',' ',x))\n",
        "new_txt = new_txt.apply(lambda x: re.sub(r'\\S*.com\\S*',' ',x))\n",
        "new_txt = new_txt.apply(lambda x: re.sub(r'\\S*@\\S*',' ',x))\n",
        "\n",
        "#remove white space\n",
        "for text in new_txt:\n",
        "  text = text.rstrip()\n",
        "\n",
        "#remove digits\n",
        "new_txt = new_txt.apply(lambda x: re.sub(r'\\d+',' ',x))\n",
        "\n",
        "#lowercase\n",
        "new_txt = new_txt.str.lower()\n",
        "\n",
        "new_txt = new_txt.apply(lambda x:lemmatizer(x))\n",
        "new_txt = new_txt.apply(lambda x: remove_stopwords(x))\n",
        "new_txt = new_txt.apply(lambda x: re.sub(\"[^a-z A-Z]\",' ',x))\n",
        "new_txt = new_txt.apply(lambda x: re.sub(r'\\W*\\b\\w{1,2}\\b',' ',x))\n",
        "new_txt = new_txt.replace(r'\\s+', ' ', regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf1sQA0T5QEV"
      },
      "source": [
        "### **1.sentiment_embedding feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PYbTEb5pxa8"
      },
      "outputs": [],
      "source": [
        "def vader_score_generation(df,e):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    polarity_Score = e.apply(lambda x: analyzer.polarity_scores(x))\n",
        "    new_df = polarity_Score.apply(pd.Series)\n",
        "    return  new_df\n",
        "\n",
        "emo_pos_dist_pscore = vader_score_generation(df,new_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj7J75bxCQwo"
      },
      "outputs": [],
      "source": [
        "df = df.join(emo_pos_dist_pscore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt0_rwasnYR0"
      },
      "source": [
        "### **2.Readability Analysis feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Vv7NjmGgA1Xx",
        "outputId": "b57a6597-b35b-4a0a-965f-1609dc1bbe19"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n2.\\n#score of 9.3 means that a ninth-grader would be able to read the document.\\nprint('flesch_kincaid_grade')\\nprint(textstat.flesch_kincaid_grade(text))\\n\\n3.\\n#6.5, then the grade level to comprehend the text is 6th to 7th grade.\\nprint('automated_readability_index')\\nprint(textstat.automated_readability_index(text))\\n\""
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def readability_ease(text):\n",
        "\n",
        "  score = textstat.flesch_reading_ease(text)\n",
        "  if 90 >= score >= 100 :\n",
        "    ease = 9\n",
        "\n",
        "  elif 80>= score <= 89 :\n",
        "    ease = 8\n",
        "\n",
        "  elif 70>= score <= 79 :\n",
        "    ease = 7\n",
        "\n",
        "  elif 60>= score <= 69 :\n",
        "    ease = 6\n",
        "\n",
        "  elif 50>= score <= 59 :\n",
        "    ease = 5\n",
        "\n",
        "  elif 30>= score <= 49 :\n",
        "    ease = 3\n",
        "\n",
        "  else :\n",
        "    ease = 0\n",
        "\n",
        "  return(ease)\n",
        "\n",
        "\n",
        "def read_time(text):\n",
        "  second = textstat.reading_time(text, ms_per_char=70)\n",
        "  return(second)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V48trIoTpvF5"
      },
      "outputs": [],
      "source": [
        "df['readability_ease'] = new_txt.apply(lambda x:readability_ease(x))\n",
        "df['read_time'] = new_txt.apply(lambda x:read_time(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHsioPA3Yesu"
      },
      "source": [
        "### **3spell checker feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaINhqlgeLWf"
      },
      "outputs": [],
      "source": [
        "def spell(text):\n",
        "\n",
        "    spell = SpellChecker()\n",
        "    wordlist = text.split()\n",
        "    miss = list(spell.unknown(wordlist))\n",
        "    amount_miss = len(miss)\n",
        "    return(amount_miss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ooOxGK9g-0N"
      },
      "outputs": [],
      "source": [
        "df['incorrect_spell'] = new_txt.apply(lambda x:spell(x))\n",
        "len_data = new_txt.apply(lambda x:len(x))\n",
        "df['incorrect_spell_freq'] = len_data / df['incorrect_spell']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAfRv6_t4jBe"
      },
      "source": [
        "### **4.Name Entity Recognition(NER) feature**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "spacy library contain these entities:\n",
        " ['CARDINAL','DATE','EVENT','FAC','GPE','LANGUAGE','LAW','LOC','MONEY','NORP','ORDINAL','ORG','PERCENT','PERSON','PRODUCT','QUANTITY','TIME', 'WORK_OF_ART']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzjtPh0hWApi"
      },
      "outputs": [],
      "source": [
        "def ner_text_count(t):\n",
        "  doc = nlp(t)\n",
        "  labels = [x.label_ for x in doc.ents]\n",
        "  count = (len(Counter(labels).keys()))\n",
        "  return(count)\n",
        "\n",
        "\n",
        "def ner_text_list(text,label):\n",
        "  doc = nlp(text)\n",
        "  labels = [x.label_ for x in doc.ents]\n",
        "  ner = [ ]\n",
        "  for l in label:\n",
        "    c = labels.count(l)\n",
        "    ner.append(c)\n",
        "  return(ner)\n",
        "\n",
        "\n",
        "all_ents = nlp.get_pipe('ner').labels\n",
        "all_ents = list(all_ents)\n",
        "df['ner_count'] = new_txt.apply(lambda x:ner_text_count(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q5-LM_YOAZk"
      },
      "source": [
        "### **5.POS feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px7_qd8248-Z"
      },
      "outputs": [],
      "source": [
        "def generate_pos_tag_dist(news_text):\n",
        "\n",
        "    counts = []\n",
        "    for sentences in news_text:\n",
        "        sentences = re.sub(r'[^\\w\\s]','',sentences)\n",
        "        tokens = nltk.word_tokenize(sentences)\n",
        "        tags = nltk.pos_tag(tokens)\n",
        "        counts.append(Counter( tag for word,  tag in tags))\n",
        "\n",
        "    df_pos_dist = pd.DataFrame.from_records(counts)\n",
        "    df_post_dist_non_null = df_pos_dist.loc[:,df_pos_dist.columns[df_pos_dist.isnull().mean() < 0.7]].reset_index()\n",
        "    df_post_dist_non_null.fillna(0,inplace=True)\n",
        "\n",
        "    return(df_post_dist_non_null)\n",
        "\n",
        "\n",
        "pos_df = generate_pos_tag_dist(new_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAXrcWBO48-a"
      },
      "outputs": [],
      "source": [
        "def zerolistmaker(n):\n",
        "    listofzeros = [0] * n\n",
        "    return listofzeros\n",
        "\n",
        "\n",
        "def group_pos_features(pos_tagged_df,pos_tagged_df2):\n",
        "\n",
        "    pos_list1 = ['DT','EX','FW','IN','MD','TO','UH']\n",
        "    pos_list2 = ['CC','CD','JJ','JJR','JJS','NN','NNP','NNS','NNPS','RBR','RB','RBS','VB','VBD','VBG','VBN','VBP','VBZ','PRP','PRP$','WDT','WP','WP$','WRB']\n",
        "\n",
        "    pos_dict = {}\n",
        "\n",
        "    for pos_l in pos_list1:\n",
        "      if pos_l in pos_tagged_df.columns:\n",
        "        pos_tagged_df2[pos_l] = np.array(list(pos_tagged_df[pos_l]))\n",
        "\n",
        "\n",
        "    for pos_l in pos_list2:\n",
        "      if pos_l in pos_tagged_df.columns:\n",
        "        pos_dict[pos_l] = np.array(list(pos_tagged_df[pos_l]))\n",
        "      else:\n",
        "        pos_dict[pos_l] = list(zerolistmaker(len(pos_tagged_df)))\n",
        "\n",
        "\n",
        "    pos_tagged_df2['group_c'] = np.sum([pos_dict['CC'],pos_dict['CD']], axis=0)\n",
        "    pos_tagged_df2['group_j'] = np.sum([pos_dict['JJ'],pos_dict['JJR'], pos_dict['JJS']], axis=0)\n",
        "    pos_tagged_df2['group_n'] = np.sum([pos_dict['NN'],pos_dict['NNS'],pos_dict['NNP'],pos_dict['NNPS']], axis=0)\n",
        "    pos_tagged_df2['group_p'] = np.sum([pos_dict['PRP'],pos_dict['PRP$']], axis=0)\n",
        "    pos_tagged_df2['group_r'] = np.sum([pos_dict['RBR'],pos_dict['RBS'],pos_dict['RB']], axis=0)\n",
        "    pos_tagged_df2['group_v'] = np.sum([pos_dict['VB'],pos_dict['VBD'], pos_dict['VBG'], pos_dict['VBN'],  pos_dict['VBP'],  pos_dict['VBZ']], axis=0)\n",
        "    pos_tagged_df2['group_w'] = np.sum([pos_dict['WDT'],pos_dict['WP'], pos_dict['WP$'], pos_dict['WRB']], axis=0)\n",
        "\n",
        "\n",
        "    return pos_tagged_df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtOGs-5LUH2P"
      },
      "outputs": [],
      "source": [
        "dataframe = group_pos_features(pos_df,df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guJjeczev9sC"
      },
      "source": [
        "### **6.cunting-statistic** features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elNrW_q1HlOt"
      },
      "outputs": [],
      "source": [
        "#Returns the number of words with a syllable count greater than or equal to 3.\n",
        "def polysyllab_count(text):\n",
        "  return(textstat.polysyllabcount(text))\n",
        "\n",
        "#Returns the number of words with a syllable count equal to one.\n",
        "def monosyllab_count(text):\n",
        "  return(textstat.monosyllabcount(text))\n",
        "\n",
        "#Number of sentences\n",
        "def count_sent(text):\n",
        "  return(textstat.sentence_count(text))\n",
        "\n",
        "#Number of capital words(all of char is upper)\n",
        "def count_capital_words(text):\n",
        "    return sum(map(str.isupper,text.split()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFFdXw_RSSnk"
      },
      "outputs": [],
      "source": [
        "df['polysyllab_count'] = new_txt.apply(lambda x:polysyllab_count(x))\n",
        "df['monosyllab_count'] = new_txt.apply(lambda x:monosyllab_count(x))\n",
        "df['sent_count'] = new_txt.apply(lambda x:count_sent(x))\n",
        "df['capital_word_count'] = new_txt.apply(lambda x:count_capital_words(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAj9P7ShUFWG"
      },
      "source": [
        "## **Learn model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuPm0lBPUdOC"
      },
      "outputs": [],
      "source": [
        "df.drop(['Id', 'newsText', 'prep_text'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkLBAyhOakG1",
        "outputId": "2e78598e-8f79-428e-9a5f-9846cb5e58b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13495, 20) (5784, 20)\n",
            "(13495, 20) (5784, 20)\n"
          ]
        }
      ],
      "source": [
        "array = df.values\n",
        "columns = df.columns\n",
        "X = array[:,1:]\n",
        "Y = array[:,0]\n",
        "y = Y.astype('int')\n",
        "\n",
        "\n",
        "data_scaler = StandardScaler().fit(X)\n",
        "data_rescaled = data_scaler.transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "\n",
        "X_train_scl, X_test_scl, y_train_scl, y_test_scl = train_test_split(data_rescaled,Y, test_size=0.3, random_state=0)\n",
        "\n",
        "print(X_train_scl.shape, X_test_scl.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(y_test, y_pred):\n",
        "\n",
        "  score = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred, average='binary')\n",
        "  recall = recall_score(y_test, y_pred, average= 'binary')\n",
        "  score_f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "  print(f'Accuracy: {round(score*100,2)}%')\n",
        "  print('precision: %.3f' % precision)\n",
        "  print('Recall: %.3f' % recall)\n",
        "  print('F-Measure: %.3f' % score_f1)\n",
        "\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  report = classification_report(y_test, y_pred)\n",
        "  print('confusion_matrix:','\\n',cm,'\\n')\n",
        "  print('classification_report:','\\n',report,'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgkYH9EObBWA"
      },
      "outputs": [],
      "source": [
        "#1-------------------------------------------------------------\n",
        "def RandomForest(tfidf_train,y_train,tfidf_test,y_test):\n",
        "  print(\"RandomForestClassifier\")\n",
        "  classifier3 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "  classifier3.fit(tfidf_train, y_train)\n",
        "  y_predR = classifier3.predict(tfidf_test)\n",
        "  evaluate(y_test, y_predR)\n",
        "\n",
        "#2-------------------------------------------------------------\n",
        "def PassiveAggressive(tfidf_train,y_train,tfidf_test,y_test):\n",
        "  print(\"Passive Aggressive Classifier\")\n",
        "  pac=PassiveAggressiveClassifier(max_iter=50)\n",
        "  pac.fit(tfidf_train,y_train)\n",
        "  y_pred=pac.predict(tfidf_test)\n",
        "  evaluate(y_test,y_pred)\n",
        "\n",
        "#3-------------------------------------------------------------\n",
        "def SVMclassifier(tfidf_train,y_train,tfidf_test,y_test):\n",
        "  print(\"svm Classifier\")\n",
        "  SVM = SVC(C=1.9, kernel='linear')\n",
        "  SVM.fit(tfidf_train, y_train)\n",
        "  svm_predictions = SVM.predict(tfidf_test)\n",
        "  evaluate(y_test, svm_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('1.RandomForest')\n",
        "RandomForest(X_train_scl,y_train_scl,X_test_scl,y_test_scl)\n",
        "\n",
        "print('2.PassiveAggressive')\n",
        "PassiveAggressive(X_train_scl,y_train_scl,X_test_scl,y_test_scl)\n",
        "\n",
        "print('3.SVM')\n",
        "SVMclassifier(X_train_scl,y_train_scl,X_test_scl,y_test_scl)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3OsnBYmFzxIq",
        "nt0_rwasnYR0",
        "FiDstvVg28PM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
